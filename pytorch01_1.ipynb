{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f0007f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar value: 0\n",
      "Rank: 0, Shape: ()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "scalar = np.array(0) #안에 들어있는 값\n",
    "print(f'Scalar value: {scalar}') \n",
    "print(f'Rank: {scalar.ndim}, Shape: {scalar.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2683a03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector values: [0 1 2 3 4 5 6]\n",
      "Rank: 1, Shape: (7,)\n"
     ]
    }
   ],
   "source": [
    "vector = np.array([0, 1, 2, 3, 4, 5, 6])\n",
    "print(f'Vector values: {vector}') #벡터는 1차원\n",
    "print(f'Rank: {vector.ndim}, Shape: {vector.shape}') #shape: 안의 원소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b55e86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix values: \n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "Rank: 2, Shape: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "# (batch, data)\n",
    "matrix = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "#대괄호 안에 또 대괄호, 대괄호 하나가 벡터하나, 벡터들이 모여서 차원이 증가\n",
    "\n",
    "print(f'Matrix values: \\n{matrix}')\n",
    "print(f'Rank: {matrix.ndim}, Shape: {matrix.shape}') #2차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df409178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor values: \n",
      "[[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]]\n",
      "\n",
      " [[ 6  7]\n",
      "  [ 8  9]\n",
      "  [10 11]]]\n",
      "Rank: 3, Shape: (2, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "# (batch, width, height)\n",
    "tensor = np.array([[[0, 1], [2, 3], [4, 5]], [[6, 7], [8, 9], [10, 11]]]) #2차원짜리 2개\n",
    "print(f'Tensor values: \\n{tensor}')\n",
    "print(f'Rank: {tensor.ndim}, Shape: {tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8250cabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor values: \n",
      "[[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]]\n",
      "\n",
      " [[ 6  7]\n",
      "  [ 8  9]\n",
      "  [10 11]]\n",
      "\n",
      " [[12 13]\n",
      "  [14 15]\n",
      "  [16 17]]]\n",
      "Rank: 3, Shape: (3, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "# (batch, width, height)\n",
    "\n",
    "#2차원짜리 3개 -> rank:3\n",
    "tensor = np.array([[[0, 1], [2, 3], [4, 5]], [[6, 7], [8, 9], [10, 11]], [[12, 13],[14,15],[16,17]]])\n",
    "print(f'Tensor values: \\n{tensor}')\n",
    "print(f'Rank: {tensor.ndim}, Shape: {tensor.shape}') #shape(겹쳐진 행렬의 수(1), 행렬의 모양(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7dfc167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "t[0]: tensor([0, 1, 2]), t[-1]: tensor([6, 7, 8])\n",
      "t[:2]: tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "t[1:]: tensor([[3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "Rank: 2, Shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# torch-based Tensor\n",
    "import torch\n",
    "\n",
    "t = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) #3개의 벡터, rank 2 tensor\n",
    "print(f'Tensor values: \\n{t}')\n",
    "print(f't[0]: {t[0]}, t[-1]: {t[-1]}') #행렬의 0번째 요소, 맨 마지막 요소(-1)를 출력\n",
    "print(f't[:2]: {t[:2]}') #tensor의 2번째 요소까지 자름: 0, 1 출력\n",
    "print(f't[1:]: {t[1:]}') #tensor의 1번째 요소부터: 1, 2 출력\n",
    "print(f'Rank: {t.dim()}, Shape: {t.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e1d4bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor values: \n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [2, 3, 4],\n",
      "         [5, 6, 7]]])\n",
      "t[0]: tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]), t[-1]: tensor([[0, 1, 2],\n",
      "        [2, 3, 4],\n",
      "        [5, 6, 7]])\n",
      "t[:2]: tensor([[[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [2, 3, 4],\n",
      "         [5, 6, 7]]])\n",
      "t[1:]: tensor([[[0, 1, 2],\n",
      "         [2, 3, 4],\n",
      "         [5, 6, 7]]])\n",
      "Rank: 3, Shape: torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "#3차원 tensor\n",
    "\n",
    "t = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],[[0, 1, 2], [2, 3, 4], [5, 6, 7]]])\n",
    "print(f'Tensor values: \\n{t}')\n",
    "print(f't[0]: {t[0]}, t[-1]: {t[-1]}')\n",
    "print(f't[:2]: {t[:2]}')\n",
    "print(f't[1:]: {t[1:]}')\n",
    "print(f'Rank: {t.dim()}, Shape: {t.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c339e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3])\n",
      "tensor([4, 7])\n",
      "tensor([5, 5])\n",
      "tensor([[4, 5],\n",
      "        [5, 6]])\n",
      "tensor([[ 8, 11],\n",
      "        [ 8, 11]])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting\n",
    "# Same shape\n",
    "print(torch.tensor([1, 4]) + torch.tensor([2, -1]))\n",
    "\n",
    "# Vector + Scalar\n",
    "print(torch.tensor([1, 4]) + torch.tensor([3]))\n",
    "\n",
    "print(torch.tensor([2, 2]) + torch.tensor([3]))\n",
    "# 3 -> [3, 3,]\n",
    "\n",
    "# 1 x 2 vector + 2 x 1 vector\n",
    "print(torch.tensor([1, 2]) + torch.tensor([[3], [4]]))\n",
    "#차원 모양이 다른 것들을 더 하면 예상하지 못하는 모양이 나올 수 있음\n",
    "\n",
    "# 1 x 2 vector + 2 x 1 vector\n",
    "print(torch.tensor([1, 4]) + torch.tensor([[7], [7]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "472396fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2]) torch.Size([2, 1])\n",
      "Matrix multiplication: \n",
      "tensor([[ 5],\n",
      "        [11]]) \n",
      "tensor([[ 5],\n",
      "        [11]])\n",
      "Elementwise multiplication: \n",
      "tensor([[1, 2],\n",
      "        [6, 8]]) \n",
      "tensor([[1, 2],\n",
      "        [6, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication vs. Elementwise multiplication\n",
    "m1 = torch.tensor([[1, 2], [3, 4]]) # 2 x 2\n",
    "m2 = torch.tensor([[1], [2]]) # 2 x 1\n",
    "print(m1.shape, m2.shape)\n",
    "\n",
    "#[1*1 + 2*2], [3*1 + 4*2]\n",
    "print(f'Matrix multiplication: \\n{m1.matmul(m2)} \\n{m1 @ m2}') \n",
    "\n",
    "#[1, 2]에는 1이 곱함, [3, 4]에는 2가 곱함\n",
    "print(f'Elementwise multiplication: \\n{m1.mul(m2)} \\n{m1 * m2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24793e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor(1.2910)\n"
     ]
    }
   ],
   "source": [
    "# Mean and Standard deviation # Cannot be calculated on integers\n",
    "t = torch.tensor([[1., 2.], [3., 4.]])\n",
    "print(t.mean())\n",
    "print(t.mean(dim=0))\n",
    "print(t.mean(dim=1))\n",
    "print(t.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "842d60b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "# Summation\n",
    "t = torch.tensor([[1., 2.], [3., 4.]])\n",
    "print(t.sum())\n",
    "print(t.sum(dim=0))\n",
    "print(t.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "008615a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "Max: tensor([3., 4.]), Argmax: tensor([1, 1])\n",
      "Max: tensor([2., 4.]), Argmax: tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Max and Argmax\n",
    "t = torch.tensor([[1., 2.], [3., 4.]])\n",
    "print(t.max())\n",
    "# With specified dimension, the first is the maximum\n",
    "# and the second is the argmax.\n",
    "#dim 차원 지정해서 최댓값 출력\n",
    "\n",
    "#dim=0 은 행따라 출력\n",
    "print(f'Max: {t.max(dim=0)[0]}, Argmax: {t.max(dim=0)[1]}') #Argmax 가장 큰 값이 있는 위치 반환\n",
    "\n",
    "#dim=1은 열따라 출력\n",
    "print(f'Max: {t.max(dim=1)[0]}, Argmax: {t.max(dim=1)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89e1434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "Max: tensor([1, 1]), Argmax: tensor([1, 1])\n",
      "Max: tensor([2., 4.]), Argmax: tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Max and Argmax\n",
    "t = torch.tensor([[1., 2.], [3., 4.]])\n",
    "print(t.max()) #최댓값 출력\n",
    "# With specified dimension, the first is the maximum\n",
    "# and the second is the argmax.\n",
    "print(f'Max: {t.max(dim=0)[1]}, Argmax: {t.max(dim=0)[1]}')\n",
    "print(f'Max: {t.max(dim=1)[0]}, Argmax: {t.max(dim=1)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "867633fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "torch.Size([4, 3])\n",
      "tensor([[[ 0,  1,  2]],\n",
      "\n",
      "        [[ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11]]])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# View (reshape) #reshape와 비슷, 모양이 달라짐. 상상과 달라질 때가 있음\n",
    "t = torch.tensor([[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]) \n",
    "#두개의 tensor가 따로 행렬로 묶어져 있음\n",
    "print(t.shape)\n",
    "\n",
    "#여기서 -1은 남는 숫자 아무거나 넣어달라\n",
    "print(t.view([-1, 3])) # '-1' for automatic calculation.\n",
    "print(t.view([-1, 3]).shape)\n",
    "\n",
    "print(t.view([-1, 1, 3]))\n",
    "print(t.view([-1, 1, 3]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25427065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11],\n",
      "        [12, 13, 14],\n",
      "        [15, 16, 17]])\n",
      "torch.Size([6, 3])\n",
      "tensor([[[ 0,  1,  2]],\n",
      "\n",
      "        [[ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14]],\n",
      "\n",
      "        [[15, 16, 17]]])\n",
      "torch.Size([6, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 6*3\n",
    "t = torch.tensor([[[0, 1, 2], [3, 4, 5]], \n",
    "                  [[6, 7, 8], [9, 10, 11]], \n",
    "                  [[12, 13, 14],[15, 16, 17]]])\n",
    "print(t.shape)\n",
    "\n",
    "#여기서 -1은 남는 숫자 아무거나 넣어달라\n",
    "print(t.view([-1, 3])) # '-1' for automatic calculation.\n",
    "print(t.view([-1, 3]).shape)\n",
    "\n",
    "print(t.view([-1, 1, 3])) #중간에 차원이 하나씩 추가 됨\n",
    "print(t.view([-1, 1, 3]).shape) # [3, 2, 3]에서 [6, 1, 3]이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7357362b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3]])\n",
      "torch.Size([4, 1])\n",
      "tensor([0, 1, 2, 3])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Squeeze\n",
    "t = torch.tensor([[0], [1], [2], [3]]) #불필요하게 하나씩 더 들어가있ㅇ름\n",
    "print(t)\n",
    "print(t.shape)\n",
    "print(t.squeeze())\n",
    "print(t.squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b44e5dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "torch.Size([4])\n",
      "tensor([1, 2, 3, 4])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Squeeze\n",
    "t = torch.tensor([1, 2, 3, 4]) #불필요하게 하나씩 더 들어가있음 없애주면 어떻게 결과 달라지는지\n",
    "print(t)\n",
    "print(t.shape)\n",
    "print(t.squeeze())\n",
    "print(t.squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79513a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 3]])\n",
      "torch.Size([1, 2])\n",
      "tensor([0, 3])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Squeeze\n",
    "t = torch.tensor([[0, 3]]) #불필요하게 하나씩 더 들어가있ㅇ름\n",
    "print(t)\n",
    "print(t.shape)\n",
    "print(t.squeeze())\n",
    "print(t.squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f7e89f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Concatenation 모양을 바꾸는 연산\n",
    "t1 = torch.tensor([[1, 2], [3, 4]])\n",
    "t2 = torch.tensor([[5, 6], [7, 8]])\n",
    "print(torch.cat([t1, t2], dim=0)) # 4 x 2\n",
    "print(torch.cat([t1, t2], dim=1)) # 2 x 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04179e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Stacking 모양을 바꾸는 연산\n",
    "t1 = torch.tensor([1, 4])\n",
    "t2 = torch.tensor([2, 5])\n",
    "t3 = torch.tensor([3, 6])\n",
    "print(torch.stack([t1, t2, t3])) # 3 x 2\n",
    "print(torch.stack([t1, t2, t3], dim=1)) # 2 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88a88f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Ones and Zeros\n",
    "t = torch.tensor([[3, 1, -2], [5, 0, 4]])\n",
    "print(t.shape)\n",
    "\n",
    "print(torch.ones_like(t)) #[2,3]으로 된 1로 이루어진 tensor가 나옴\n",
    "print(torch.zeros_like(t)) #[2, 3]으로 된 0으로 이루어진 tensor가 나옴\n",
    "#딥러닝 할 때는 이런 0, 1로 이루어진 tensor들을 사용할 일이 많음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b093f1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0, 0],\n",
      "        [0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Ones and Zeros\n",
    "t = torch.tensor([[3, 1], [5, 0]]) #모양을 다르게 해도 됨\n",
    "print(t.shape)\n",
    "print(torch.ones_like(t))\n",
    "print(torch.zeros_like(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e865c8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Ones and Zeros\n",
    "t = torch.tensor([[3, 1, 100], [5, 90, 4]]) #내용이 어떻든 모양만 잘 잡아줌\n",
    "print(t.shape)\n",
    "print(torch.ones_like(t))\n",
    "print(torch.zeros_like(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38ad873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[ 6., 12.],\n",
      "        [18., 24.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[12., 24.],\n",
      "        [36., 48.]])\n",
      "tensor([[12., 24.],\n",
      "        [36., 48.]])\n"
     ]
    }
   ],
   "source": [
    "# In-place Operation\n",
    "t = torch.tensor([[1., 2.], [3., 4.]])\n",
    "print(t.mul(2.)) #2를 모든 원소에 곱해준다\n",
    "print(t) #처음에 선언된 t가 유지됨\n",
    "\n",
    "print(t.mul(6.)) #각 원소에 6씩 곱하고\n",
    "print(t) #처음 t 유지\n",
    "\n",
    "print(t.mul_(2.)) #t에 mul_하면 유지를 해줌\n",
    "print(t) #그대로 남아있음을 볼 수 있음\n",
    "\n",
    "print(t.mul_(6.)) #t에 mul_하면 유지를 해줌\n",
    "print(t) #그대로 남아있음을 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd4d491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
